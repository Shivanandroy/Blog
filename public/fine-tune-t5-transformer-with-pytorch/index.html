<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Fine Tuning T5 Transformer Model with PyTorch - Shivanand Roy | Deep Learning</title>

        <link rel="alternate" href="http://shivanandroy.com/index.xml" type="application/rss+xml" title="Shivanand Roy | Deep Learning"/><meta name="Description" content="In this article, you will learn how to fine tune a T5 model with PyTorch and transformers"><meta property="og:title" content="Fine Tuning T5 Transformer Model with PyTorch" />
<meta property="og:description" content="In this article, you will learn how to fine tune a T5 model with PyTorch and transformers" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" />
<meta property="og:image" content="http://shivanandroy.com/posts/dl/images/fine-tune-t5.png" />
<meta property="article:published_time" content="2021-02-08T00:42:27+05:30" />
<meta property="article:modified_time" content="2021-02-08T00:42:27+05:30" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://shivanandroy.com/posts/dl/images/fine-tune-t5.png"/>

<meta name="twitter:title" content="Fine Tuning T5 Transformer Model with PyTorch"/>
<meta name="twitter:description" content="In this article, you will learn how to fine tune a T5 model with PyTorch and transformers"/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" /><link rel="prev" href="http://shivanandroy.com/visualizing-game-of-thrones-with-bert/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Fine Tuning T5 Transformer Model with PyTorch",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/shivanandroy.com\/fine-tune-t5-transformer-with-pytorch\/"
        },"genre": "posts","keywords": "Deep Learning, Transformers, T5","wordcount":  2344 ,
        "url": "http:\/\/shivanandroy.com\/fine-tune-t5-transformer-with-pytorch\/","datePublished": "2021-02-08T00:42:27+05:30","dateModified": "2021-02-08T00:42:27+05:30","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Shivanand Roy"
            },"description": "In this article, you will learn how to fine tune a T5 model with PyTorch and transformers"
    }
    </script>
		    <script data-ad-client="ca-pub-1337012385171026" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    </head>
    <body header-desktop="fixed" header-mobile="auto"><script defer type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Shivanand Roy | Deep Learning"><span class="header-title-pre"><span style="font-size:23px"><span style="font-family:Manrope"><span style="color:#454444">shivanand</span><span style="color:#d14f4f">roy</span></span></span></span></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/dl/" title="Deep Learning"> Deep Learning </a><a class="menu-item" href="/posts/ml/" title="Machine Learning"> Machine Learning </a><a class="menu-item" href="/posts/codebase/" title="Code Base"> Code Base </a><a class="menu-item" href="/categories/" title="Categories"> Categories </a><a class="menu-item" href="/tags/" title="Tags"> Tags </a><a class="menu-item" href="/subscribe/" title="Subscribe🚀"> Subscribe🚀 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Shivanand Roy | Deep Learning"><span class="header-title-pre"><span style="font-size:23px"><span style="font-family:Manrope"><span style="color:#454444">shivanand</span><span style="color:#d14f4f">roy</span></span></span></span></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/dl/" title="Deep Learning">Deep Learning</a><a class="menu-item" href="/posts/ml/" title="Machine Learning">Machine Learning</a><a class="menu-item" href="/posts/codebase/" title="Code Base">Code Base</a><a class="menu-item" href="/categories/" title="Categories">Categories</a><a class="menu-item" href="/tags/" title="Tags">Tags</a><a class="menu-item" href="/subscribe/" title="Subscribe🚀">Subscribe🚀</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content always-active" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Fine Tuning T5 Transformer Model with PyTorch</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://shivanandroy.com" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>Shivanand Roy</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="08/02/2021">08/02/2021</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;2344 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;12 minutes&nbsp;</div>
        </div><div class="featured-image"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/posts/dl/images/fine-tune-t5.png"
        data-srcset="/posts/dl/images/fine-tune-t5.png, /posts/dl/images/fine-tune-t5.png 1.5x, /posts/dl/images/fine-tune-t5.png 2x"
        data-sizes="auto"
        alt="/posts/dl/images/fine-tune-t5.png"
        title="In this article, you will learn how to fine tune a T5 model with PyTorch and transformers" /></div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#data">Data</a></li>
    <li><a href="#lets-code">Let&rsquo;s Code</a>
      <ul>
        <li><a href="#import-libraries">Import Libraries</a></li>
        <li><a href="#dataset-class">Dataset Class</a></li>
        <li><a href="#train-steps">Train steps</a></li>
        <li><a href="#validation-steps">Validation steps</a></li>
        <li><a href="#t5-trainer">T5 Trainer</a></li>
        <li><a href="#model-parameters">Model Parameters</a></li>
        <li><a href="#lets-call-t5trainer">Let&rsquo;s call T5Trainer</a></li>
      </ul>
    </li>
    <li><a href="#notebooks">Notebooks</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><div class="details admonition abstract open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-list-ul fa-fw"></i>Abstract<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>In this article, you will learn how to fine tune a T5 transformer model using <code>PyTorch</code> &amp; <code>Transformers🤗</code></p>
<p><a href="https://colab.research.google.com/drive/1eoQUsisoPmc0e-bpjSKYYd-TE1F5YTqG?usp=sharing" target="_blank" rel="noopener noreffer"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://colab.research.google.com/assets/colab-badge.svg"
        data-srcset="https://colab.research.google.com/assets/colab-badge.svg, https://colab.research.google.com/assets/colab-badge.svg 1.5x, https://colab.research.google.com/assets/colab-badge.svg 2x"
        data-sizes="auto"
        alt="https://colab.research.google.com/assets/colab-badge.svg"
        title="Open In Colab" /></a>
<a href="https://github.com/Shivanandroy/T5-Finetuning-PyTorch" target="_blank" rel="noopener noreffer"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://img.shields.io/badge/Go%20to%20GitHub-Repository-green"
        data-srcset="https://img.shields.io/badge/Go%20to%20GitHub-Repository-green, https://img.shields.io/badge/Go%20to%20GitHub-Repository-green 1.5x, https://img.shields.io/badge/Go%20to%20GitHub-Repository-green 2x"
        data-sizes="auto"
        alt="https://img.shields.io/badge/Go%20to%20GitHub-Repository-green"
        title="Go to GitHub Repository" /></a></p>
</div>
        </div>
    </div>
<h2 id="introduction">Introduction</h2>
<p>A <code>T5</code> is an encoder-decoder model. It converts all NLP problems like language translation, summarization, text generation, question-answering, to a text-to-text task.</p>
<p>For e.g., in case of <strong>translation</strong>, T5 accepts <code>source text</code>: English, as input and tries to convert it into <code>target text</code>: Serbian: </p>
<table>
<thead>
<tr>
<th>source text</th>
<th>target text</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hey, there!</td>
<td>Хеј тамо!</td>
</tr>
<tr>
<td>I&rsquo;m going to train a T5 model with PyTorch</td>
<td>Обучићу модел Т5 са ПиТорцх-ом</td>
</tr>
</tbody>
</table>
<p>In case of <strong>summarization</strong>, source text or input can be a long description and target text can just be a one line summary. </p>
<table>
<thead>
<tr>
<th>source text</th>
<th>target text</th>
</tr>
</thead>
<tbody>
<tr>
<td>&ldquo;Saurav Kant, an alumnus of upGrad and IIIT-B&rsquo;s PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad&rsquo;s 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad&rsquo;s Online Power Learning has powered 3 lakh+ careers.&rdquo;</td>
<td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>
</tr>
</tbody>
</table>
<p>In this article, we will take a pretrained <code>T5-base</code> model and fine tune it to generate a one line summary of news articles using <code>PyTorch</code>.</p>
<h2 id="data">Data</h2>
<p>We will take a news summary dataset: It has 2 columns:</p>
<ul>
<li><code>text</code> : article content</li>
<li><code>headlines</code> : one line summary of article content</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="n">path</span> <span class="o">=</span> <span class="s2">&#34;https://raw.githubusercontent.com/Shivanandroy/T5-Finetuning-PyTorch/main/data/news_summary.csv&#34;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="n">dh</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

</code></pre></td></tr></table>
</div>
</div><table>
<thead>
<tr>
<th>text</th>
<th>headlines</th>
</tr>
</thead>
<tbody>
<tr>
<td>&ldquo;Kunal Shah&rsquo;s credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.&rdquo;</td>
<td>Delhi techie wins free food from Swiggy for one year on CRED</td>
</tr>
<tr>
<td>New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma&rsquo;s captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.&quot;</td>
<td>New Zealand end Rohit Sharma-led India&rsquo;s 12-match winning streak</td>
</tr>
<tr>
<td>With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â\x82¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.'</td>
<td>Aegon life iTerm insurance plan helps customers save tax</td>
</tr>
<tr>
<td>Isha Ghosh, an 81-year-old member of Bharat Scouts and Guides (BSG), has been imparting physical and mental training to schoolchildren in Jharkhand for several decades. Chaibasa-based Ghosh reportedly walks seven kilometres daily and spends eight hours conducting physical training, apart from climbing and yoga sessions. She says, &ldquo;One should do something for society till one's last breath.&quot;'</td>
<td>81-yr-old woman conducts physical training in J&rsquo;khand schools</td>
</tr>
</tbody>
</table>
<h2 id="lets-code">Let&rsquo;s Code</h2>
<p><code>PyTorch</code> has a standard way to train any deep learning model. We will first start by writing a <code>Dataset</code> class, followed by <code>training</code>, <code>validation</code> steps and then a main <code>T5Trainer</code> function that will fine-tune our model.</p>
<p>But first let&rsquo;s install all the dependent modules and import them</p>
<h3 id="import-libraries">Import Libraries</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">sentencepiece</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">rich</span><span class="p">[</span><span class="n">jupyter</span><span class="p">]</span>

<span class="c1"># Importing libraries</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Importing the T5 modules from huggingface/transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">T5Tokenizer</span><span class="p">,</span> <span class="n">T5ForConditionalGeneration</span>

<span class="c1"># rich: for a better display on terminal</span>
<span class="kn">from</span> <span class="nn">rich.table</span> <span class="kn">import</span> <span class="n">Column</span><span class="p">,</span> <span class="n">Table</span>
<span class="kn">from</span> <span class="nn">rich</span> <span class="kn">import</span> <span class="n">box</span>
<span class="kn">from</span> <span class="nn">rich.console</span> <span class="kn">import</span> <span class="n">Console</span>

<span class="c1"># define a rich console logger</span>
<span class="n">console</span> <span class="o">=</span> <span class="n">Console</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># to display dataframe in ASCII format</span>
<span class="k">def</span> <span class="nf">display_df</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;display dataframe in ASCII format&#34;&#34;&#34;</span>

    <span class="n">console</span> <span class="o">=</span> <span class="n">Console</span><span class="p">()</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">Table</span><span class="p">(</span>
        <span class="n">Column</span><span class="p">(</span><span class="s2">&#34;source_text&#34;</span><span class="p">,</span> <span class="n">justify</span><span class="o">=</span><span class="s2">&#34;center&#34;</span><span class="p">),</span>
        <span class="n">Column</span><span class="p">(</span><span class="s2">&#34;target_text&#34;</span><span class="p">,</span> <span class="n">justify</span><span class="o">=</span><span class="s2">&#34;center&#34;</span><span class="p">),</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&#34;Sample Data&#34;</span><span class="p">,</span>
        <span class="n">pad_edge</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="n">box</span><span class="o">=</span><span class="n">box</span><span class="o">.</span><span class="n">ASCII</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()):</span>
        <span class="n">table</span><span class="o">.</span><span class="n">add_row</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>

<span class="c1"># training logger to log training progress</span>
<span class="n">training_logger</span> <span class="o">=</span> <span class="n">Table</span><span class="p">(</span>
    <span class="n">Column</span><span class="p">(</span><span class="s2">&#34;Epoch&#34;</span><span class="p">,</span> <span class="n">justify</span><span class="o">=</span><span class="s2">&#34;center&#34;</span><span class="p">),</span>
    <span class="n">Column</span><span class="p">(</span><span class="s2">&#34;Steps&#34;</span><span class="p">,</span> <span class="n">justify</span><span class="o">=</span><span class="s2">&#34;center&#34;</span><span class="p">),</span>
    <span class="n">Column</span><span class="p">(</span><span class="s2">&#34;Loss&#34;</span><span class="p">,</span> <span class="n">justify</span><span class="o">=</span><span class="s2">&#34;center&#34;</span><span class="p">),</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&#34;Training Status&#34;</span><span class="p">,</span>
    <span class="n">pad_edge</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">box</span><span class="o">=</span><span class="n">box</span><span class="o">.</span><span class="n">ASCII</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Setting up the device for GPU usage</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">cuda</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>

</code></pre></td></tr></table>
</div>
</div><h3 id="dataset-class">Dataset Class</h3>
<p>We will write a <code>Dataset</code> class for reading our dataset and loading it into the dataloader and then feed it to the neural network for fine tuning the model.</p>
<p>This class will take 6 arguments as input:</p>
<ul>
<li><code>dataframe (pandas.DataFrame)</code>: Input dataframe</li>
<li><code>tokenizer (transformers.tokenizer)</code>: T5 tokenizer</li>
<li><code>source_len (int)</code>: Max length of source text</li>
<li><code>target_len (int)</code>: Max length of target text</li>
<li><code>source_text (str)</code>: column name of source text</li>
<li><code>target_text (str)</code> : column name of target text</li>
</ul>
<p>This class will have 2 methods:</p>
<ul>
<li><code>__len__</code>: returns the length of the dataframe</li>
<li><code>__getitem__</code>: return the input ids, attention masks and target ids</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">YourDataSetClass</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Creating a custom dataset for reading the dataset and
</span><span class="s2">    loading it into the dataloader to pass it to the
</span><span class="s2">    neural network for finetuning the model
</span><span class="s2">
</span><span class="s2">    &#34;&#34;&#34;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dataframe</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">source_len</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span>
    <span class="p">):</span>
        <span class="s2">&#34;&#34;&#34;
</span><span class="s2">        Initializes a Dataset class
</span><span class="s2">
</span><span class="s2">        Args:
</span><span class="s2">            dataframe (pandas.DataFrame): Input dataframe
</span><span class="s2">            tokenizer (transformers.tokenizer): Transformers tokenizer
</span><span class="s2">            source_len (int): Max length of source text
</span><span class="s2">            target_len (int): Max length of target text
</span><span class="s2">            source_text (str): column name of source text
</span><span class="s2">            target_text (str): column name of target text
</span><span class="s2">        &#34;&#34;&#34;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">dataframe</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source_len</span> <span class="o">=</span> <span class="n">source_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summ_len</span> <span class="o">=</span> <span class="n">target_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">target_text</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">source_text</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&#34;&#34;&#34;returns the length of dataframe&#34;&#34;&#34;</span>

        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_text</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="s2">&#34;&#34;&#34;return the input ids, attention masks and target ids&#34;&#34;&#34;</span>

        <span class="n">source_text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source_text</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="n">target_text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_text</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>

        <span class="c1"># cleaning data so as to ensure data is in string type</span>
        <span class="n">source_text</span> <span class="o">=</span> <span class="s2">&#34; &#34;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
        <span class="n">target_text</span> <span class="o">=</span> <span class="s2">&#34; &#34;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

        <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span>
            <span class="p">[</span><span class="n">source_text</span><span class="p">],</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">source_len</span><span class="p">,</span>
            <span class="n">pad_to_max_length</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;max_length&#34;</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&#34;pt&#34;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span>
            <span class="p">[</span><span class="n">target_text</span><span class="p">],</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">summ_len</span><span class="p">,</span>
            <span class="n">pad_to_max_length</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&#34;max_length&#34;</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&#34;pt&#34;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">source_ids</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="s2">&#34;input_ids&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">source_mask</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="s2">&#34;attention_mask&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">target_ids</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="s2">&#34;input_ids&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">target_mask</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="s2">&#34;attention_mask&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&#34;source_ids&#34;</span><span class="p">:</span> <span class="n">source_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
            <span class="s2">&#34;source_mask&#34;</span><span class="p">:</span> <span class="n">source_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
            <span class="s2">&#34;target_ids&#34;</span><span class="p">:</span> <span class="n">target_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
            <span class="s2">&#34;target_ids_y&#34;</span><span class="p">:</span> <span class="n">target_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
        <span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="train-steps">Train steps</h3>
<p><code>train</code> function will the put model on training mode, generate outputs and calculate loss</p>
<p>This will take 6 arguments as input:</p>
<ul>
<li><code>epoch</code>: epoch</li>
<li><code>tokenizer</code>: T5 tokenizer</li>
<li><code>model</code>: T5 model</li>
<li><code>loader</code>: Train Dataloader</li>
<li><code>optimizer</code>: Optimizer</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>

    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Function to be called for training with the parameters passed from main function
</span><span class="s2">
</span><span class="s2">    &#34;&#34;&#34;</span>

    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;target_ids&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">y_ids</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">lm_labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">lm_labels</span><span class="p">[</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;source_ids&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;source_mask&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
            <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">y_ids</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">lm_labels</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">_</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">training_logger</span><span class="o">.</span><span class="n">add_row</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">epoch</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">_</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
            <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="n">training_logger</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

</code></pre></td></tr></table>
</div>
</div><h3 id="validation-steps">Validation steps</h3>
<p><code>validate</code> function is same as the <code>train</code> function, but for the validation data</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">loader</span><span class="p">):</span>

  <span class="s2">&#34;&#34;&#34;
</span><span class="s2">  Function to evaluate model for predictions
</span><span class="s2">
</span><span class="s2">  &#34;&#34;&#34;</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">actuals</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
          <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
          <span class="n">ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;source_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
          <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;source_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

          <span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
              <span class="n">input_ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">,</span>
              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">,</span> 
              <span class="n">max_length</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> 
              <span class="n">num_beams</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
              <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> 
              <span class="n">length_penalty</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> 
              <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
              <span class="p">)</span>
          <span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">generated_ids</span><span class="p">]</span>
          <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span>
          <span class="k">if</span> <span class="n">_</span><span class="o">%</span><span class="mi">10</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
              <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Completed {_}&#39;</span><span class="p">)</span>

          <span class="n">predictions</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
          <span class="n">actuals</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">actuals</span>

</code></pre></td></tr></table>
</div>
</div><h3 id="t5-trainer">T5 Trainer</h3>
<p><code>T5Trainer</code> is our main function. It accepts input data, model type, model paramters to fine-tune the model. Under the hood, it utilizes, our <code>Dataset</code> class for data handling, <code>train</code> function to fine tune the model, <code>validate</code> to evaluate the model.</p>
<p><code>T5Trainer</code> will have 5 arguments:</p>
<ul>
<li><code>dataframe</code>: Input dataframe</li>
<li><code>source_text</code>: Column name of the input text i.e. article content</li>
<li><code>target_text</code>: Column name of the taregt text i.e. one line summary</li>
<li><code>model_params</code>: T5 model parameters</li>
<li><code>output_dir</code>: Output directory to save fine tuned T5 model.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">T5Trainer</span><span class="p">(</span>
    <span class="n">dataframe</span><span class="p">,</span> <span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">model_params</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s2">&#34;./outputs/&#34;</span>
<span class="p">):</span>

    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    T5 trainer
</span><span class="s2">
</span><span class="s2">    &#34;&#34;&#34;</span>

    <span class="c1"># Set random seeds and deterministic pytorch for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;SEED&#34;</span><span class="p">])</span>  <span class="c1"># pytorch random seed</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;SEED&#34;</span><span class="p">])</span>  <span class="c1"># numpy random seed</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="c1"># logging</span>
    <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;&#34;&#34;[Model]: Loading {model_params[&#34;MODEL&#34;]}...</span><span class="se">\n</span><span class="s2">&#34;&#34;&#34;</span><span class="p">)</span>

    <span class="c1"># tokenzier for encoding the text</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">T5Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;MODEL&#34;</span><span class="p">])</span>

    <span class="c1"># Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary.</span>
    <span class="c1"># Further this model is sent to device (GPU/TPU) for using the hardware.</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">T5ForConditionalGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;MODEL&#34;</span><span class="p">])</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># logging</span>
    <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;[Data]: Reading data...</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="c1"># Importing the raw dataset</span>
    <span class="n">dataframe</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[[</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">]]</span>
    <span class="n">display_df</span><span class="p">(</span><span class="n">dataframe</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Creation of Dataset and Dataloader</span>
    <span class="c1"># Defining the train size. So 80% of the data will be used for training and the rest for validation.</span>
    <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.8</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;SEED&#34;</span><span class="p">])</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;FULL Dataset: {dataframe.shape}&#34;</span><span class="p">)</span>
    <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;TRAIN Dataset: {train_dataset.shape}&#34;</span><span class="p">)</span>
    <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;TEST Dataset: {val_dataset.shape}</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="c1"># Creating the Training and Validation dataset for further creation of Dataloader</span>
    <span class="n">training_set</span> <span class="o">=</span> <span class="n">YourDataSetClass</span><span class="p">(</span>
        <span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;MAX_SOURCE_TEXT_LENGTH&#34;</span><span class="p">],</span>
        <span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;MAX_TARGET_TEXT_LENGTH&#34;</span><span class="p">],</span>
        <span class="n">source_text</span><span class="p">,</span>
        <span class="n">target_text</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">val_set</span> <span class="o">=</span> <span class="n">YourDataSetClass</span><span class="p">(</span>
        <span class="n">val_dataset</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;MAX_SOURCE_TEXT_LENGTH&#34;</span><span class="p">],</span>
        <span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;MAX_TARGET_TEXT_LENGTH&#34;</span><span class="p">],</span>
        <span class="n">source_text</span><span class="p">,</span>
        <span class="n">target_text</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Defining the parameters for creation of dataloaders</span>
    <span class="n">train_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&#34;batch_size&#34;</span><span class="p">:</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;TRAIN_BATCH_SIZE&#34;</span><span class="p">],</span>
        <span class="s2">&#34;shuffle&#34;</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="s2">&#34;num_workers&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">val_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&#34;batch_size&#34;</span><span class="p">:</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;VALID_BATCH_SIZE&#34;</span><span class="p">],</span>
        <span class="s2">&#34;shuffle&#34;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
        <span class="s2">&#34;num_workers&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.</span>
    <span class="n">training_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">training_set</span><span class="p">,</span> <span class="o">**</span><span class="n">train_params</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_set</span><span class="p">,</span> <span class="o">**</span><span class="n">val_params</span><span class="p">)</span>

    <span class="c1"># Defining the optimizer that will be used to tune the weights of the network in the training session.</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
        <span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;LEARNING_RATE&#34;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Training loop</span>
    <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;[Initiating Fine Tuning]...</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;TRAIN_EPOCHS&#34;</span><span class="p">]):</span>
        <span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">training_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

    <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;[Saving Model]...</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="c1"># Saving the model after training</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&#34;model_files&#34;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

    <span class="c1"># evaluating test dataset</span>
    <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;[Initiating Validation]...</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">model_params</span><span class="p">[</span><span class="s2">&#34;VAL_EPOCHS&#34;</span><span class="p">]):</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">actuals</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
        <span class="n">final_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&#34;Generated Text&#34;</span><span class="p">:</span> <span class="n">predictions</span><span class="p">,</span> <span class="s2">&#34;Actual Text&#34;</span><span class="p">:</span> <span class="n">actuals</span><span class="p">})</span>
        <span class="n">final_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&#34;predictions.csv&#34;</span><span class="p">))</span>

    <span class="n">console</span><span class="o">.</span><span class="n">save_text</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&#34;logs.txt&#34;</span><span class="p">))</span>

    <span class="n">console</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;[Validation Completed.]</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span>
        <span class="n">f</span><span class="s2">&#34;&#34;&#34;[Model] Model saved @ {os.path.join(output_dir, &#34;model_files&#34;)}</span><span class="se">\n</span><span class="s2">&#34;&#34;&#34;</span>
    <span class="p">)</span>
    <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span>
        <span class="n">f</span><span class="s2">&#34;&#34;&#34;[Validation] Generation on Validation data saved @ {os.path.join(output_dir,&#39;predictions.csv&#39;)}</span><span class="se">\n</span><span class="s2">&#34;&#34;&#34;</span>
    <span class="p">)</span>
    <span class="n">console</span><span class="o">.</span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;&#34;&#34;[Logs] Logs saved @ {os.path.join(output_dir,&#39;logs.txt&#39;)}</span><span class="se">\n</span><span class="s2">&#34;&#34;&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="model-parameters">Model Parameters</h3>
<p><code>model_params</code> is a dictionary containing model paramters for T5 training:</p>
<ul>
<li><code>MODEL: &quot;t5-base&quot;</code>,  model_type: t5-base/t5-large</li>
<li><code>TRAIN_BATCH_SIZE: 8</code>,  training batch size</li>
<li><code>VALID_BATCH_SIZE: 8</code>,  validation batch size</li>
<li><code>TRAIN_EPOCHS: 3</code>,  number of training epochs</li>
<li><code>VAL_EPOCHS: 1</code>,  number of validation epochs</li>
<li><code>LEARNING_RATE: 1e-4</code>,  learning rate</li>
<li><code>MAX_SOURCE_TEXT_LENGTH: 512</code>,  max length of source text</li>
<li><code>MAX_TARGET_TEXT_LENGTH: 50</code>,   max length of target text</li>
<li><code>SEED: 42</code>,  set seed for reproducibility</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python">
<span class="c1"># let&#39;s define model parameters specific to T5</span>
<span class="n">model_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&#34;MODEL&#34;</span><span class="p">:</span> <span class="s2">&#34;t5-base&#34;</span><span class="p">,</span>  <span class="c1"># model_type: t5-base/t5-large</span>
    <span class="s2">&#34;TRAIN_BATCH_SIZE&#34;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>  <span class="c1"># training batch size</span>
    <span class="s2">&#34;VALID_BATCH_SIZE&#34;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>  <span class="c1"># validation batch size</span>
    <span class="s2">&#34;TRAIN_EPOCHS&#34;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>  <span class="c1"># number of training epochs</span>
    <span class="s2">&#34;VAL_EPOCHS&#34;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># number of validation epochs</span>
    <span class="s2">&#34;LEARNING_RATE&#34;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>  <span class="c1"># learning rate</span>
    <span class="s2">&#34;MAX_SOURCE_TEXT_LENGTH&#34;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>  <span class="c1"># max length of source text</span>
    <span class="s2">&#34;MAX_TARGET_TEXT_LENGTH&#34;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>  <span class="c1"># max length of target text</span>
    <span class="s2">&#34;SEED&#34;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>  <span class="c1"># set seed for reproducibility</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="lets-call-t5trainer">Let&rsquo;s call T5Trainer</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># T5 accepts prefix of the task to be performed:</span>
<span class="c1"># Since we are summarizing, let&#39;s add summarize to source text as a prefix</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&#34;text&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;summarize: &#34;</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s2">&#34;text&#34;</span><span class="p">]</span>

<span class="n">T5Trainer</span><span class="p">(</span>
    <span class="n">dataframe</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">source_text</span><span class="o">=</span><span class="s2">&#34;text&#34;</span><span class="p">,</span>
    <span class="n">target_text</span><span class="o">=</span><span class="s2">&#34;headlines&#34;</span><span class="p">,</span>
    <span class="n">model_params</span><span class="o">=</span><span class="n">model_params</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&#34;outputs&#34;</span><span class="p">,</span>
<span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">                              Training Status                               
+--------------------------------------------------------------------------+
|Epoch | Steps |                            Loss                           |
|------+-------+-----------------------------------------------------------|
|  0   |   0   | tensor(8.5338, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  0   |  10   | tensor(3.4278, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  0   |  20   | tensor(3.0148, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  0   |  30   | tensor(3.2338, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  0   |  40   | tensor(2.5963, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  1   |   0   | tensor(2.2411, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  1   |  10   | tensor(1.9470, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  1   |  20   | tensor(1.9091, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  1   |  30   | tensor(2.0122, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  1   |  40   | tensor(1.5261, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  2   |   0   | tensor(1.6496, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  2   |  10   | tensor(1.1971, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  2   |  20   | tensor(1.6908, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  2   |  30   | tensor(1.4069, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
|  2   |  40   | tensor(2.1261, device=&#39;cuda:0&#39;, grad_fn=&lt;NllLossBackward&gt;)|
+--------------------------------------------------------------------------+
</code></pre></td></tr></table>
</div>
</div><h2 id="notebooks">Notebooks</h2>
<div class="details admonition success open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-check-circle fa-fw"></i>Attachments<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><ul>
<li><a href="https://raw.githubusercontent.com/Shivanandroy/T5-Finetuning-PyTorch/main/data/news_summary.csv" target="_blank" rel="noopener noreffer">Go to Dataset</a>.</li>
<li><a href="https://github.com/Shivanandroy/T5-Finetuning-PyTorch/blob/main/notebook/T5_Fine_tuning_with_PyTorch.ipynb" target="_blank" rel="noopener noreffer">Go to Notebook</a></li>
<li><a href="https://colab.research.google.com/drive/1eoQUsisoPmc0e-bpjSKYYd-TE1F5YTqG?usp=sharing" target="_blank" rel="noopener noreffer"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://colab.research.google.com/assets/colab-badge.svg"
        data-srcset="https://colab.research.google.com/assets/colab-badge.svg, https://colab.research.google.com/assets/colab-badge.svg 1.5x, https://colab.research.google.com/assets/colab-badge.svg 2x"
        data-sizes="auto"
        alt="https://colab.research.google.com/assets/colab-badge.svg"
        title="Open In Colab" /></a></li>
<li><a href="https://github.com/Shivanandroy/T5-Finetuning-PyTorch" target="_blank" rel="noopener noreffer"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://img.shields.io/badge/Go%20to%20GitHub-Repository-green"
        data-srcset="https://img.shields.io/badge/Go%20to%20GitHub-Repository-green, https://img.shields.io/badge/Go%20to%20GitHub-Repository-green 1.5x, https://img.shields.io/badge/Go%20to%20GitHub-Repository-green 2x"
        data-sizes="auto"
        alt="https://img.shields.io/badge/Go%20to%20GitHub-Repository-green"
        title="Go to GitHub Repository" /></a></li>
</ul>
</div>
        </div>
    </div></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 08/02/2021</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" data-title="Fine Tuning T5 Transformer Model with PyTorch" data-via="snrspeaks" data-hashtags="Deep Learning,Transformers,T5"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" data-hashtag="Deep Learning"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" data-title="Fine Tuning T5 Transformer Model with PyTorch" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" data-title="Fine Tuning T5 Transformer Model with PyTorch"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" data-title="Fine Tuning T5 Transformer Model with PyTorch" data-image="/posts/dl/images/fine-tune-t5.png"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="Share on Myspace" data-sharer="myspace" data-url="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" data-title="Fine Tuning T5 Transformer Model with PyTorch" data-description="In this article, you will learn how to fine tune a T5 model with PyTorch and transformers"><i data-svg-src="/lib/simple-icons/icons/myspace.min.svg"></i></a><a href="javascript:void(0);" title="Share on Blogger" data-sharer="blogger" data-url="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" data-title="Fine Tuning T5 Transformer Model with PyTorch" data-description="In this article, you will learn how to fine tune a T5 model with PyTorch and transformers"><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="Share on Evernote" data-sharer="evernote" data-url="http://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/" data-title="Fine Tuning T5 Transformer Model with PyTorch"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/deep-learning/">Deep Learning</a>,&nbsp;<a href="/tags/transformers/">Transformers</a>,&nbsp;<a href="/tags/t5/">T5</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/visualizing-game-of-thrones-with-bert/" class="prev" rel="prev" title="Visualizing Game of Thrones with BERT"><i class="fas fa-angle-left fa-fw"></i>Visualizing Game of Thrones with BERT</a></div>
</div>
<div id="comments"><div id="utterances"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">Utterances</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><a href="/policy/">Privacy & Policies</a>&nbsp&nbsp|&nbsp&nbsp<a href="/contact/">Contact Us</a></div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://shivanandroy.com" target="_blank">Shivanand Roy</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/lightgallery/lightgallery.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/twemoji/twemoji.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":1000},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"title","label":"","lightTheme":"github-light","repo":"Shivanandroy/Blog"}},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"},"twemoji":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-177212842-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-177212842-1" async></script></body>
</html>
