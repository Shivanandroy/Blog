<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Natural Language Understanding - Category - Shivanand Roy | Deep Learning</title>
        <link>http://shivanandroy.com/categories/natural-language-understanding/</link>
        <description>Natural Language Understanding - Category - Shivanand Roy | Deep Learning</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>iamshivanandroy@gmail.com (Shivanand Roy)</managingEditor>
            <webMaster>iamshivanandroy@gmail.com (Shivanand Roy)</webMaster><lastBuildDate>Fri, 13 Nov 2020 00:42:27 &#43;0530</lastBuildDate><atom:link href="http://shivanandroy.com/categories/natural-language-understanding/" rel="self" type="application/rss+xml" /><item>
    <title>Visualizing Game of Thrones with BERT</title>
    <link>http://shivanandroy.com/visualizing-game-of-thrones-with-bert/</link>
    <pubDate>Fri, 13 Nov 2020 00:42:27 &#43;0530</pubDate>
    <author>Author</author>
    <guid>http://shivanandroy.com/visualizing-game-of-thrones-with-bert/</guid>
    <description><![CDATA[In this article, we will visualize Game of Thrones books with BERT in 3D space.]]></description>
</item><item>
    <title>Building A Faster &amp; Accurate COVID Search Engine with TransformersðŸ¤—</title>
    <link>http://shivanandroy.com/building-a-faster-accurate-covid-search-engine-with-transformers/</link>
    <pubDate>Wed, 14 Oct 2020 00:42:27 &#43;0530</pubDate>
    <author>Author</author>
    <guid>http://shivanandroy.com/building-a-faster-accurate-covid-search-engine-with-transformers/</guid>
    <description><![CDATA[This article is a step by step guide to build a faster and accurate COVID Semantic Search Engine using HuggingFace TransformersðŸ¤—. In this article, we will build a search engine, which will not only retrieve and rank the articles based on the query but also give us the response, along with a 1000 words context around the response]]></description>
</item><item>
    <title>Building Question Answering Model at Scale using ðŸ¤—Transformers</title>
    <link>http://shivanandroy.com/transformers-building-question-answers-model-at-scale/</link>
    <pubDate>Mon, 12 Oct 2020 00:42:27 &#43;0530</pubDate>
    <author>Author</author>
    <guid>http://shivanandroy.com/transformers-building-question-answers-model-at-scale/</guid>
    <description><![CDATA[In this article, you will learn how to fetch contextual answers in a huge corpus of documents using TransformersðŸ¤—. We will build a neural question and answering system using transformers models (`RoBERTa`). This approach is capable to perform Q&A across millions of documents in few seconds.]]></description>
</item></channel>
</rss>
